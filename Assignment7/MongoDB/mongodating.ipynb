{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5cadba-9357-4aa3-9fab-28fd8d568282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import csv\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "# Third party imports\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Local imports\n",
    "from utils import diff_cols, grid_search, prepare_dataset, pymongo_loads\n",
    "\n",
    "# File definitions\n",
    "csv_src = Path(\"/import/SpeedDatingData.csv\")\n",
    "\n",
    "# Preprocessing inputs\n",
    "query_cols = {\n",
    "    \"iid\": 1,\n",
    "    \"pid\": 1,\n",
    "    \"age\": 1,\n",
    "    \"age_o\": 1,\n",
    "    \"dec\": 1,\n",
    "    \"dec_o\": 1,\n",
    "    \"attr\": 1,\n",
    "    \"attr_o\": 1,\n",
    "    \"sinc\": 1,\n",
    "    \"sinc_o\": 1,\n",
    "    \"intel\": 1,\n",
    "    \"intel_o\": 1,\n",
    "    \"fun\": 1,\n",
    "    \"fun_o\": 1,\n",
    "    \"amb\": 1,\n",
    "    \"amb_o\": 1,\n",
    "    \"shar\": 1,\n",
    "    \"shar_o\": 1,\n",
    "    \"match\": 1,\n",
    "}\n",
    "diff_cols_ = [\"age\", \"dec\", \"attr\", \"sinc\", \"intel\", \"fun\", \"amb\", \"shar\"]\n",
    "y_cols = [\"match\"]\n",
    "\n",
    "# model inputs\n",
    "test_size = 0.2\n",
    "random_state = 777\n",
    "max_depths = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c9a270-3b9c-4cbc-a922-6664dd596910",
   "metadata": {},
   "source": [
    "## Provide outputs from mongosh CLI\n",
    "\n",
    "1. List databases\n",
    "    ```\n",
    "    test> show databases;\n",
    "    admin         40.00 KiB\n",
    "    config       108.00 KiB\n",
    "    local         72.00 KiB\n",
    "    speeddating   45.16 MiB\n",
    "    ```\n",
    "2. Use speeddating database\n",
    "    ```\n",
    "    test> use speeddating;\n",
    "    switched to db speeddating\n",
    "    speeddating>\n",
    "    ```\n",
    "3. Show collections\n",
    "    ```\n",
    "    speeddating> show collections;\n",
    "    events\n",
    "    ```\n",
    "4. Show one of the collection documents\n",
    "    ```\n",
    "    speeddating> db.events.findOne();\n",
    "    {\n",
    "      _id: ObjectId(\"640e841e5ef008fcacb6f359\"),\n",
    "      iid: '1',\n",
    "      id: '1',\n",
    "      gender: '0',\n",
    "      idg: '1',\n",
    "      condtn: '1',\n",
    "      wave: '1',\n",
    "      round: '10',\n",
    "      position: '7',\n",
    "      positin1: '',\n",
    "      order: '4',\n",
    "      partner: '1',\n",
    "      pid: '11',\n",
    "      match: '0',\n",
    "      int_corr: '0.14',\n",
    "      samerace: '0',\n",
    "      age_o: '27',\n",
    "      race_o: '2',\n",
    "      pf_o_att: '35',\n",
    "      pf_o_sin: '20',\n",
    "      pf_o_int: '20',\n",
    "      pf_o_fun: '20',\n",
    "      pf_o_amb: '0',\n",
    "      pf_o_sha: '5',\n",
    "      dec_o: '0',\n",
    "      attr_o: '6',\n",
    "      sinc_o: '8',\n",
    "      intel_o: '8',\n",
    "      fun_o: '8',\n",
    "      amb_o: '8',\n",
    "      shar_o: '6',\n",
    "      like_o: '7',\n",
    "      prob_o: '4',\n",
    "      met_o: '2',\n",
    "      age: '21',\n",
    "      field_cd: '1',\n",
    "      undergra: '',\n",
    "      mn_sat: '',\n",
    "      tuition: '',\n",
    "      race: '4',\n",
    "      imprace: '2',\n",
    "      imprelig: '4',\n",
    "      from: 'Chicago',\n",
    "      zipcode: '60521',\n",
    "      income: '69487',\n",
    "      goal: '2',\n",
    "      date: '7',\n",
    "      go_out: '1',\n",
    "      career: 'lawyer',\n",
    "      career_c: '',\n",
    "      sports: '9',\n",
    "      tvsports: '2',\n",
    "      exercise: '8',\n",
    "      dining: '9',\n",
    "      museums: '1',\n",
    "      art: '1',\n",
    "      hiking: '5',\n",
    "      gaming: '1',\n",
    "      clubbing: '5',\n",
    "      reading: '6',\n",
    "      tv: '9',\n",
    "      theater: '1',\n",
    "      movies: '10',\n",
    "      concerts: '10',\n",
    "      music: '9',\n",
    "      shopping: '8',\n",
    "      yoga: '1',\n",
    "      exphappy: '3',\n",
    "      expnum: '2',\n",
    "      attr1_1: '15',\n",
    "      sinc1_1: '20',\n",
    "      intel1_1: '20',\n",
    "      fun1_1: '15',\n",
    "      amb1_1: '15',\n",
    "      shar1_1: '15',\n",
    "      attr4_1: '',\n",
    "      sinc4_1: '',\n",
    "      intel4_1: '',\n",
    "      fun4_1: '',\n",
    "      amb4_1: '',\n",
    "      shar4_1: '',\n",
    "      attr2_1: '35',\n",
    "      sinc2_1: '20',\n",
    "      intel2_1: '15',\n",
    "      fun2_1: '20',\n",
    "      amb2_1: '5',\n",
    "      shar2_1: '5',\n",
    "      attr3_1: '6',\n",
    "      sinc3_1: '8',\n",
    "      fun3_1: '8',\n",
    "      intel3_1: '8',\n",
    "      amb3_1: '7',\n",
    "      attr5_1: '',\n",
    "      sinc5_1: '',\n",
    "      intel5_1: '',\n",
    "      fun5_1: '',\n",
    "      amb5_1: '',\n",
    "      dec: '1',\n",
    "      attr: '6',\n",
    "      sinc: '9',\n",
    "      intel: '7',\n",
    "      fun: '7',\n",
    "      amb: '6',\n",
    "      shar: '5',\n",
    "      like: '7',\n",
    "      prob: '6',\n",
    "      met: '2',\n",
    "      match_es: '4',\n",
    "      attr1_s: '',\n",
    "      sinc1_s: '',\n",
    "      intel1_s: '',\n",
    "      fun1_s: '',\n",
    "      amb1_s: '',\n",
    "      shar1_s: '',\n",
    "      attr3_s: '',\n",
    "      sinc3_s: '',\n",
    "      intel3_s: '',\n",
    "      fun3_s: '',\n",
    "      amb3_s: '',\n",
    "      satis_2: '6',\n",
    "      length: '2',\n",
    "      numdat_2: '1',\n",
    "      attr7_2: '',\n",
    "      sinc7_2: '',\n",
    "      intel7_2: '',\n",
    "      fun7_2: '',\n",
    "      amb7_2: '',\n",
    "      shar7_2: '',\n",
    "      attr1_2: '19.44',\n",
    "      sinc1_2: '16.67',\n",
    "      intel1_2: '13.89',\n",
    "      fun1_2: '22.22',\n",
    "      amb1_2: '11.11',\n",
    "      shar1_2: '16.67',\n",
    "      attr4_2: '',\n",
    "      sinc4_2: '',\n",
    "      intel4_2: '',\n",
    "      fun4_2: '',\n",
    "      amb4_2: '',\n",
    "      shar4_2: '',\n",
    "      attr2_2: '',\n",
    "      sinc2_2: '',\n",
    "      intel2_2: '',\n",
    "      fun2_2: '',\n",
    "      amb2_2: '',\n",
    "      shar2_2: '',\n",
    "      attr3_2: '6',\n",
    "      sinc3_2: '7',\n",
    "      intel3_2: '8',\n",
    "      fun3_2: '7',\n",
    "      amb3_2: '6',\n",
    "      attr5_2: '',\n",
    "      sinc5_2: '',\n",
    "      intel5_2: '',\n",
    "      fun5_2: '',\n",
    "      amb5_2: '',\n",
    "      you_call: '1',\n",
    "      them_cal: '1',\n",
    "      date_3: '0',\n",
    "      numdat_3: '',\n",
    "      num_in_3: '',\n",
    "      attr1_3: '15',\n",
    "      sinc1_3: '20',\n",
    "      intel1_3: '20',\n",
    "      fun1_3: '15',\n",
    "      amb1_3: '15',\n",
    "      shar1_3: '15',\n",
    "      attr7_3: '',\n",
    "      sinc7_3: '',\n",
    "      intel7_3: '',\n",
    "      fun7_3: '',\n",
    "      amb7_3: '',\n",
    "      shar7_3: '',\n",
    "      attr4_3: '',\n",
    "      sinc4_3: '',\n",
    "      intel4_3: '',\n",
    "      fun4_3: '',\n",
    "      amb4_3: '',\n",
    "      shar4_3: '',\n",
    "      attr2_3: '',\n",
    "      sinc2_3: '',\n",
    "      intel2_3: '',\n",
    "      fun2_3: '',\n",
    "      amb2_3: '',\n",
    "      shar2_3: '',\n",
    "      attr3_3: '5',\n",
    "      sinc3_3: '7',\n",
    "      intel3_3: '7',\n",
    "      fun3_3: '7',\n",
    "      amb3_3: '7',\n",
    "      attr5_3: '',\n",
    "      sinc5_3: '',\n",
    "      intel5_3: '',\n",
    "      fun5_3: '',\n",
    "      amb5_3: ''\n",
    "    }\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da77c1f9-ab92-4dce-82c5-a12a5e9cd459",
   "metadata": {},
   "source": [
    "## Load data, prepare it, run cross-validation, and test model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853aefc7-4e3a-4c0c-a38f-679ab93a8afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Load data from /import/SpeedDatingData.csv\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Prepare data for classifier\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Split into test and train sets\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Conduct cross validation\n",
      "Cross validation results\n",
      "           acc_tr  acc_val\n",
      "max_depth                 \n",
      "1           0.823    0.823\n",
      "2           0.823    0.823\n",
      "3           0.823    0.823\n",
      "4           0.824    0.818\n",
      "5           0.830    0.814\n",
      "6           0.839    0.799\n",
      "7           0.850    0.794\n",
      "8           0.864    0.797\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Select best max depth\n",
      "Best max depth=1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Train model on training data using best max depth\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Score model on test data\n",
      "Test accuracy=0.82\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Feature importances:\n",
      "dec_diff      1.0\n",
      "age_diff      0.0\n",
      "attr_diff     0.0\n",
      "sinc_diff     0.0\n",
      "intel_diff    0.0\n",
      "fun_diff      0.0\n",
      "amb_diff      0.0\n",
      "shar_diff     0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(80 * \"~\")\n",
    "print(f\"Load data from {csv_src}\")\n",
    "collection = pymongo_loads(csv_src, \"speeddating\", \"events\")\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(f\"Prepare data for classifier\")\n",
    "df = prepare_dataset(collection, query_cols, diff_cols_)\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(\"Split into test and train sets\")\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(df.drop(axis=1, labels=y_cols), df[y_cols[0]], random_state=random_state, test_size=test_size)\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(\"Conduct cross validation\")\n",
    "validation_scores, validation_summary = grid_search(X_tr, y_tr, max_depths)\n",
    "print(\"Cross validation results\")\n",
    "print(validation_summary)\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(\"Select best max depth\")\n",
    "best_max_depth = validation_summary.index.values[validation_summary[\"acc_val\"].argmax()]\n",
    "print(f\"Best max depth={best_max_depth}\")\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(\"Train model on training data using best max depth\")\n",
    "best_model = DecisionTreeClassifier(max_depth=best_max_depth)\n",
    "best_model.fit(X_tr, y_tr)\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(\"Score model on test data\")\n",
    "acc_te = round(best_model.score(X_te, y_te), 2)\n",
    "print(f\"Test accuracy={acc_te}\")\n",
    "\n",
    "print(80 * \"~\")\n",
    "feature_importances = pd.Series(best_model.feature_importances_, index=list(X_tr)).sort_values(ascending=False)\n",
    "print(f\"Feature importances:\\n{feature_importances}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20076410-2588-4dd7-93e4-bf49d64da37c",
   "metadata": {},
   "source": [
    "# Comparison of two databases\n",
    "\n",
    "The Neo4J database better exploits the relationships inherent in the speed dating dataset. The MongoDB database, which is document-based, merely creates a list of documents. For data that is better expressed as nodes and edges (i.e., a graph), Neo4J is the better option. On the other hand, if I had a collection of documents of varying lengths and metadata, MongoDB would be the better option. A situation where Neo4J wouldn't do as well is one where I have millions of articles of varying length and metadata that I want to store, analyze, and organize."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
