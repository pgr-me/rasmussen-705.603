{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d08433f-1b69-43c2-a5d3-f6f7eb16bec8",
   "metadata": {},
   "source": [
    "# Assignment 7: Neo4J speed dating\n",
    "\n",
    "This notebook analyzes a speed dating dataset using Neo4J and models whether a date results in a match using a simple decision tree classifier.\n",
    "\n",
    "Helper functions are loaded from the `utils` module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db537d-d06f-4d28-abde-24d043882e3b",
   "metadata": {},
   "source": [
    "## Load libraries and define inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b67cbf-4a12-4810-b832-44c31077da65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "from typing import Any, List, Optional, Tuple, Type\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Local imports\n",
    "from utils import execute_cypher, grid_search, parse_cypher_output, prepare_dataset\n",
    "\n",
    "\n",
    "# Directory and filepath definitions\n",
    "root_dir = Path(\"/nosql/neo4j\")\n",
    "scripts_dir = root_dir / \"cypher\"\n",
    "data_dir = root_dir / \"data\"\n",
    "src = root_dir / \"import\" / \"speeddatingReduced.csv\"\n",
    "schema_viz_cypher_src = scripts_dir / \"schema_viz.cypher\"\n",
    "female_male_ratio_cypher_src = scripts_dir / \"female_male_ratio.cypher\"\n",
    "match_frac_cypher_src = scripts_dir / \"match_frac.cypher\"\n",
    "\n",
    "# Data preprocessing inputs\n",
    "id_cols = [\"dater\", \"datee\"]\n",
    "y_col = [\"match\"]\n",
    "attr_cols = [\"int_corr\"]\n",
    "diff_cols = [\"age\", \"race\", \"attr\", \"sinc\", \"intel\", \"fun\", \"amb\", \"shar\", \"like\", \"prob\", \"met\"]\n",
    "\n",
    "# Model inputs\n",
    "random_state = 777\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d105bf-ba44-46b1-a68b-cce97dd7308b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema_viz = parse_cypher_output(data_dir, \"schema_viz.out\", scalar=False, dtype=str)\n",
    "female_male_ratio = float(parse_cypher_output(data_dir, \"female_male_ratio.out\", scalar=True, dtype=float))\n",
    "match_frac = float(parse_cypher_output(data_dir, \"match_frac.out\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf87ae1-ed0a-487e-8a80-3d878a76fd07",
   "metadata": {},
   "source": [
    "## Execute cypher queries, parse cypher outputs, and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a561f4c7-87aa-4eaf-a097-35aa333587ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execute cypher queries\n",
      "Run Schema visualization query.\n",
      "Run query to find female: male ratio.\n",
      "Run query to find fraction of dates that resulted in matches.\n",
      "Saved outputs to /nosql/neo4j/data\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Parse cypher outputs written to /nosql/neo4j/data.\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Schema visualization: ['nodes, relationships\\n', '[(:Person {name: \"Person\", indexes: [], constraints: []})], [[:Date]]\\n']\n",
      "Female: male ratio: 1.073780\n",
      "Fraction of dates that resulted in matches: 0.162749\n"
     ]
    }
   ],
   "source": [
    "print(80 * \"~\")\n",
    "print(\"Execute cypher queries\")\n",
    "print(\"Run Schema visualization query.\")\n",
    "execute_cypher(schema_viz_cypher_src, data_dir)\n",
    "print(\"Run query to find female: male ratio.\")\n",
    "execute_cypher(female_male_ratio_cypher_src, data_dir)\n",
    "print(\"Run query to find fraction of dates that resulted in matches.\")\n",
    "execute_cypher(match_frac_cypher_src, data_dir)\n",
    "print(f\"Saved outputs to {data_dir}\")\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(f\"Parse cypher outputs written to {data_dir}.\")\n",
    "schema_viz = parse_cypher_output(data_dir, \"schema_viz.out\", scalar=False, dtype=str)\n",
    "female_male_ratio = parse_cypher_output(data_dir, \"female_male_ratio.out\")\n",
    "match_frac = parse_cypher_output(data_dir, \"match_frac.out\")\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(f\"Schema visualization: {schema_viz}\")\n",
    "print(f\"Female: male ratio: {female_male_ratio:2f}\")\n",
    "print(f\"Fraction of dates that resulted in matches: {match_frac:2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921883cd-f4d7-487e-abdd-98d67ecc7ead",
   "metadata": {},
   "source": [
    "## Load, preprocess, cross-validate, and test a simple decision tree classifier to prediction whether date is a match\n",
    "* This approach was based on the hypothesis that differences between two daters would drive match prediction.\n",
    "* The difference in whether a couple 'liked' each other was most important feature, followed by intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806168f7-63e0-4562-be4b-3db58c0521f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Load /nosql/neo4j/import/speeddatingReduced.csv\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Prepare dataset for classifier.\n",
      "Data has dimensions of (2758, 13)\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Split into train and test sets; test size=0.2.\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Conduct cross validation\n",
      "Cross validation results\n",
      "           acc_tr  acc_val\n",
      "max_depth                 \n",
      "2           0.815    0.815\n",
      "4           0.818    0.811\n",
      "6           0.827    0.794\n",
      "8           0.848    0.784\n",
      "10          0.881    0.757\n",
      "12          0.920    0.730\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Select best max depth\n",
      "Best max depth=2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Train model on training data using best max depth\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Score model on test data\n",
      "Test accuracy=0.86\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Feature importances:\n",
      "like_diff     0.734972\n",
      "intel_diff    0.150146\n",
      "attr_diff     0.114882\n",
      "int_corr      0.000000\n",
      "age_diff      0.000000\n",
      "race_diff     0.000000\n",
      "sinc_diff     0.000000\n",
      "fun_diff      0.000000\n",
      "amb_diff      0.000000\n",
      "shar_diff     0.000000\n",
      "prob_diff     0.000000\n",
      "met_diff      0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(80 * \"~\")\n",
    "print(f\"Load {src}\")\n",
    "df_ = pd.read_csv(src)\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(\"Prepare dataset for classifier.\")\n",
    "df = prepare_dataset(df_, id_cols, y_col, attr_cols, diff_cols)\n",
    "print(f\"Data has dimensions of {df.shape}\")\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(f\"Split into train and test sets; test size={test_size}.\")\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(df.drop(axis=1, labels=y_col), df[y_col[0]], random_state=random_state, test_size=test_size)\n",
    "max_depths = [2, 4, 6, 8, 10, 12]\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(\"Conduct cross validation\")\n",
    "validation_scores, validation_summary = grid_search(X_tr, y_tr, max_depths)\n",
    "print(\"Cross validation results\")\n",
    "print(validation_summary)\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(\"Select best max depth\")\n",
    "best_max_depth = validation_summary.index.values[validation_summary[\"acc_val\"].argmax()]\n",
    "print(f\"Best max depth={best_max_depth}\")\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(\"Train model on training data using best max depth\")\n",
    "best_model = DecisionTreeClassifier(max_depth=best_max_depth)\n",
    "best_model.fit(X_tr, y_tr)\n",
    "\n",
    "print(80 * \"~\")\n",
    "print(\"Score model on test data\")\n",
    "acc_te = round(best_model.score(X_te, y_te), 2)\n",
    "print(f\"Test accuracy={acc_te}\")\n",
    "\n",
    "print(80 * \"~\")\n",
    "feature_importances = pd.Series(best_model.feature_importances_, index=list(X_tr)).sort_values(ascending=False)\n",
    "print(f\"Feature importances:\\n{feature_importances}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
