{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/AlaaSedeeq/Convolutional-Autoencoder-PyTorch/blob/main/Model/Autoencoder.py\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import rasterio as rio\n",
    "from rasterio.plot import reshape_as_image\n",
    "import torch\n",
    "import torch.nn as nn   \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, Resize, RandomCrop\n",
    "\n",
    "\n",
    "from utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from collections import namedtuple\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import prepare_data, decode_label, show_examples, Swish, weight_init, compare_results\n",
    "\n",
    "# Local imports\n",
    "from mlp import ImageDataset, MLP, train_test_ae_mlp\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 1028\n",
    "DATA_DIR = Path(r\"C:\\Users\\Peter\\gh\\rasmussen-705.603\\data\\FinalProject\")\n",
    "EPOCHS = 30\n",
    "GAMMA = 0.1\n",
    "LAT_SPACE_SIZES = [2, 4, 16, 64, 256,]\n",
    "LRS = [0.5, 0.1]\n",
    "OUTPUT_BANDS = [\"blue\", \"green\", \"red\", \"nir08\", \"swir16\", \"swir22\", \"ndvi\", \"qa\"]\n",
    "STEP_SIZES = [5, 10, 15]\n",
    "TR_VAL_SPLIT = 0.9\n",
    "WEIGHT_DECAY = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "raw_dir = DATA_DIR / \"raw\"\n",
    "interim_dir = DATA_DIR / \"interim\"\n",
    "processed_dir = DATA_DIR / \"processed\"\n",
    "cogs_dir = interim_dir / \"_cogs-4-30\"\n",
    "autoencoder_dir = processed_dir / \"autoencoder\"\n",
    "models_dir = interim_dir / \"models\"\n",
    "scores_dir = interim_dir / \"scores\"\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "scores_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded = model.encoder(batch)\n",
    "# encoded = encoded.view(-1, model.CNN_flatten)\n",
    "# latent_space1 = model.latent_space1(encoded)\n",
    "# latent_space2 = model.latent_space2(latent_space1)\n",
    "# latent_space3 = model.latent_space3(latent_space2)\n",
    "# latent_space3.shape, batch.shape\n",
    "# decoded = latent_space3.view(-1, model.CNN[1], model.CNN[2], model.CNN[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2504, 279, 310)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create PyTorch datasets and loaders\n",
    "dataset = ImageDataset(cogs_dir, OUTPUT_BANDS, slice_frac=0.01)\n",
    "\n",
    "tr_val_size = int(TR_VAL_SPLIT * len(dataset))\n",
    "te_size = len(dataset) - tr_val_size\n",
    "tr_size = int(TR_VAL_SPLIT * tr_val_size)\n",
    "val_size = tr_val_size - tr_size\n",
    "\n",
    "tr_val_dataset, te_dataset = torch.utils.data.random_split(dataset, [tr_val_size, te_size])\n",
    "tr_dataset, val_dataset = torch.utils.data.random_split(tr_val_dataset, [tr_size, val_size])\n",
    "\n",
    "\n",
    "tr_loader = DataLoader(tr_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "te_loader = DataLoader(te_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "len(tr_loader), len(val_loader), len(te_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model with step_size=5 and lr=0.5.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr, weight_decay\u001b[39m=\u001b[39mWEIGHT_DECAY, fused\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mstep_size, gamma\u001b[39m=\u001b[39mGAMMA)\n\u001b[1;32m---> 22\u001b[0m \u001b[39mraise\u001b[39;00m\n\u001b[0;32m     23\u001b[0m tr_val_losses, te_losses \u001b[39m=\u001b[39m train_test_ae_mlp(\n\u001b[0;32m     24\u001b[0m     model,\n\u001b[0;32m     25\u001b[0m     tr_loader, val_loader, te_loader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     device,\n\u001b[0;32m     30\u001b[0m     )\n\u001b[0;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = EPOCHS\n",
    "\n",
    "\n",
    "tr_val_losses = []\n",
    "te_losses = []\n",
    "for step_size in STEP_SIZES:\n",
    "    for lr in LRS:\n",
    "\n",
    "        print(f\"Train model with step_size={step_size} and lr={lr}.\")\n",
    "        model = MLP(\n",
    "            in_features=8,\n",
    "            hidden_neurons=2,\n",
    "            )\n",
    "        model.to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=WEIGHT_DECAY, fused=True)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
    "        tr_val_losses_, te_losses_ = train_test_ae_mlp(\n",
    "            model,\n",
    "            tr_loader, val_loader, te_loader,\n",
    "            criterion, optimizer, scheduler,\n",
    "            lr, step_size, epochs,\n",
    "            models_dir, scores_dir,\n",
    "            device,\n",
    "        )\n",
    "        tr_val_losses.extend(tr_val_losses_)\n",
    "        te_losses.extend(te_losses_)\n",
    "\n",
    "\n",
    "tr_val_summary = pd.DataFrame(tr_val_losses)\n",
    "te_summary = pd.DataFrame(te_losses)\n",
    "\n",
    "tr_val_summary.to_csv(scores_dir / \"tr_val_summary.csv\")\n",
    "te_summary.to_csv(scores_dir / \"te_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 0.5)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_step_size = int(tr_val_summary.sort_values(by=\"val_loss\").iloc[0].to_dict()[\"step_size\"])\n",
    "optimal_lr = tr_val_summary.sort_values(by=\"val_loss\").iloc[0].to_dict()[\"lr\"]\n",
    "optimal_step_size, optimal_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_src = models_dir / f\"mlp-autoencoder-{optimal_step_size}-{optimal_lr:.3f}.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = AE(in_features=8, hidden_neurons=2)\n",
    "new_model.load_state_dict(torch.load(model_src))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
